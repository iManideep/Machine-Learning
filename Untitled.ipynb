{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3daca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import pydeequ\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4249c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9f66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ae2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.profiles import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cac63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ColumnProfilerRunner(spark) \\\n",
    "            .onData(df) \\\n",
    "            .run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75014fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydeequ.profiles.StandardColumnProfile"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columnProfileClasses['StandardColumnProfile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ece520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydeequ.profiles.NumericColumnProfile"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columnProfileClasses['NumericColumnProfile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db17b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'PassengerId'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 888\n",
      "\t datatype: Integral\n",
      "\t minimum: 1.0\n",
      "\t maximum: 891.0\n",
      "\t mean: 446.0\n",
      "\t standard deviation: 257.20938292890224\n",
      "Column 'Name'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 936\n",
      "\t datatype: String\n",
      "Column 'Ticket'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 710\n",
      "\t datatype: String\n",
      "Column 'Pclass'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 3\n",
      "\t datatype: Integral\n",
      "\t minimum: 1.0\n",
      "\t maximum: 3.0\n",
      "\t mean: 2.308641975308642\n",
      "\t standard deviation: 0.8356019334795166\n",
      "Column 'Parch'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 7\n",
      "\t datatype: Integral\n",
      "\t minimum: 0.0\n",
      "\t maximum: 6.0\n",
      "\t mean: 0.38159371492704824\n",
      "\t standard deviation: 0.8056047612452213\n",
      "Column 'Embarked'\n",
      "\t completeness: 0.9977553310886644\n",
      "\t approximate number of distinct values: 3\n",
      "\t datatype: String\n",
      "Column 'Age'\n",
      "\t completeness: 0.8013468013468014\n",
      "\t approximate number of distinct values: 83\n",
      "\t datatype: Fractional\n",
      "\t minimum: 0.42\n",
      "\t maximum: 80.0\n",
      "\t mean: 29.69911764705882\n",
      "\t standard deviation: 14.51632115081731\n",
      "Column 'Cabin'\n",
      "\t completeness: 0.22895622895622897\n",
      "\t approximate number of distinct values: 149\n",
      "\t datatype: String\n",
      "Column 'Fare'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 241\n",
      "\t datatype: Fractional\n",
      "\t minimum: 0.0\n",
      "\t maximum: 512.3292\n",
      "\t mean: 32.2042079685746\n",
      "\t standard deviation: 49.6655344447741\n",
      "Column 'SibSp'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 7\n",
      "\t datatype: Integral\n",
      "\t minimum: 0.0\n",
      "\t maximum: 8.0\n",
      "\t mean: 0.5230078563411896\n",
      "\t standard deviation: 1.1021244350892876\n",
      "Column 'Survived'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 2\n",
      "\t datatype: Integral\n",
      "\t minimum: 0.0\n",
      "\t maximum: 1.0\n",
      "\t mean: 0.3838383838383838\n",
      "\t standard deviation: 0.4863193178670999\n",
      "Column 'Sex'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 2\n",
      "\t datatype: String\n"
     ]
    }
   ],
   "source": [
    "for col, profile in result.profiles.items():\n",
    "    print(f'Column \\'{col}\\'')\n",
    "    print('\\t',f'completeness: {profile.completeness}')\n",
    "    print('\\t',f'approximate number of distinct values: {profile.approximateNumDistinctValues}')\n",
    "    print('\\t',f'datatype: {profile.dataType}')\n",
    "    if profile.dataType == 'Integral' or profile.dataType == 'Fractional':\n",
    "        print('\\t',f\"minimum: {profile.minimum}\")\n",
    "        print('\\t',f\"maximum: {profile.maximum}\")\n",
    "        print('\\t',f\"mean: {profile.mean}\")\n",
    "        print('\\t',f\"standard deviation: {profile.stdDev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acddfecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    entity  instance                        name  value\n",
      "0   Column  Survived                Completeness    1.0\n",
      "1   Column  Survived              Histogram.bins    5.0\n",
      "2   Column  Survived       Histogram.abs.Boolean    0.0\n",
      "3   Column  Survived     Histogram.ratio.Boolean    0.0\n",
      "4   Column  Survived    Histogram.abs.Fractional    0.0\n",
      "5   Column  Survived  Histogram.ratio.Fractional    0.0\n",
      "6   Column  Survived      Histogram.abs.Integral  891.0\n",
      "7   Column  Survived    Histogram.ratio.Integral    1.0\n",
      "8   Column  Survived       Histogram.abs.Unknown    0.0\n",
      "9   Column  Survived     Histogram.ratio.Unknown    0.0\n",
      "10  Column  Survived        Histogram.abs.String    0.0\n",
      "11  Column  Survived      Histogram.ratio.String    0.0\n",
      "12  Column  Survived               CountDistinct    2.0\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "\n",
    "analysisResult = AnalysisRunner(spark).onData(df)\n",
    "analysisResult= analysisResult.addAnalyzer(Completeness('Survived'))\n",
    "analysisResult= analysisResult.addAnalyzer(CountDistinct('Survived'))\n",
    "analysisResult= analysisResult.addAnalyzer(Maximum('Survived'))\n",
    "analysisResult= analysisResult.addAnalyzer(DataType('Survived'))\n",
    "analysisResult= analysisResult.run()\n",
    "a_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult, pandas = True)\n",
    "print(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a6b29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f94422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,concat,lit\n",
    "import os\n",
    "from pydeequ.analyzers import *\n",
    "import pydeequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b50d5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').option('header','true').load('Data_Profile.trg')\n",
    "source_name_file_prefix_list = df.select('source_name_file_prefix').collect()\n",
    "source_name_file_prefix_list = [i.source_name_file_prefix for i in source_name_file_prefix_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6dcd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_zone_files = os.listdir()\n",
    "feed_files = dict()\n",
    "for i in source_name_file_prefix_list:\n",
    "    feed_files[i] = [file_name for file_name in landing_zone_files if file_name.startswith(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb2b7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').option('header','true').load('Data_Profile_Config.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a6850fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"*\",concat(col(\"Source\"),lit('_'),col('File Prefix')).alias(\"source_name_file_prefix\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "289d2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee7ce2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b1dc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in feed_files:\n",
    "    list_of_analyzers = df.where(df.source_name_file_prefix == i).rdd.collect()\n",
    "    for file in feed_files[i]:\n",
    "        feed_df = spark.read.format('csv').option('header','true').load(file)\n",
    "        analysisResult = AnalysisRunner(spark).onData(feed_df)\n",
    "        for row in list_of_analyzers:\n",
    "            if row['Column Name'] is not None:\n",
    "                list_of_columns = list(map(lambda x:x.strip(),row['Column Name'].split(',')))\n",
    "                for i in list_of_columns:\n",
    "                    if row['Profile Function'] == \"Completeness\":\n",
    "                        analysisResult = analysisResult.addAnalyzer(Completeness(i))\n",
    "                    elif row['Profile Function'] == \"CountDistinct\":\n",
    "                        analysisResult = analysisResult.addAnalyzer(CountDistinct(i))\n",
    "                    elif row['Profile Function'] == \"DataType\":\n",
    "                        analysisResult = analysisResult.addAnalyzer(DataType(i))\n",
    "                    elif row['Profile Function'] == \"Maximum\":\n",
    "                        analysisResult = analysisResult.addAnalyzer(Maximum(i))\n",
    "                    elif row['Profile Function'] == \"Mean\":\n",
    "                        analysisResult = analysisResult.addAnalyzer(Mean(i))\n",
    "            else:\n",
    "                list_of_columns = None\n",
    "                if row['Profile Function'] == \"Size\":\n",
    "                    analysisResult = analysisResult.addAnalyzer(Size())\n",
    "        analysisResult = analysisResult.run()\n",
    "        analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult,pandas = True)\n",
    "        analysisResult_df['Timestamp'] = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "        analysisResult_df['Source Name'] = list_of_analyzers[0][\"Source\"]\n",
    "        analysisResult_df['File Prefix'] = list_of_analyzers[0][\"File Prefix\"]\n",
    "        analysisResult_df['File Name'] = file\n",
    "        result_df = pd.concat([result_df,analysisResult_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5589fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec217a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Run Id'] = np.arange(1,len(result_df)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04aa639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.rename(columns = {\"value\":\"Profile Result\",\"name\":\"Profile Funciton\",\"instance\":\"Column Name\"},inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25f9d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[['Run Id', 'Source Name','File Prefix', 'Column Name', 'Profile Funciton', 'Profile Result','Timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f5337e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run Id</th>\n",
       "      <th>Source Name</th>\n",
       "      <th>File Prefix</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Profile Funciton</th>\n",
       "      <th>Profile Result</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.216590</td>\n",
       "      <td>26-08-2021 14:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Sex</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26-08-2021 14:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Age</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.799539</td>\n",
       "      <td>26-08-2021 14:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Survived</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26-08-2021 14:21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>26-08-2021 14:21:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Sex</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26-08-2021 14:21:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Age</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>0.803063</td>\n",
       "      <td>26-08-2021 14:21:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SECTORAPT</td>\n",
       "      <td>Survived</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26-08-2021 14:21:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>GRDW</td>\n",
       "      <td>ASSET_CLASS</td>\n",
       "      <td>Species</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26-08-2021 14:21:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>GRDW</td>\n",
       "      <td>ASSET_CLASS</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26-08-2021 14:21:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>GRDW</td>\n",
       "      <td>ASSET_CLASS</td>\n",
       "      <td>Species</td>\n",
       "      <td>CountDistinct</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26-08-2021 14:21:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>GRDW</td>\n",
       "      <td>ASSET_CLASS</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>26-08-2021 14:21:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run Id Source Name  File Prefix Column Name Profile Funciton  \\\n",
       "0       1         ACT    SECTORAPT       Cabin     Completeness   \n",
       "1       2         ACT    SECTORAPT         Sex    CountDistinct   \n",
       "2       3         ACT    SECTORAPT         Age     Completeness   \n",
       "3       4         ACT    SECTORAPT    Survived    CountDistinct   \n",
       "0       5         ACT    SECTORAPT       Cabin     Completeness   \n",
       "1       6         ACT    SECTORAPT         Sex    CountDistinct   \n",
       "2       7         ACT    SECTORAPT         Age     Completeness   \n",
       "3       8         ACT    SECTORAPT    Survived    CountDistinct   \n",
       "0       9        GRDW  ASSET_CLASS     Species    CountDistinct   \n",
       "1      10        GRDW  ASSET_CLASS           *             Size   \n",
       "0      11        GRDW  ASSET_CLASS     Species    CountDistinct   \n",
       "1      12        GRDW  ASSET_CLASS           *             Size   \n",
       "\n",
       "   Profile Result            Timestamp  \n",
       "0        0.216590  26-08-2021 14:21:06  \n",
       "1        2.000000  26-08-2021 14:21:06  \n",
       "2        0.799539  26-08-2021 14:21:06  \n",
       "3        2.000000  26-08-2021 14:21:06  \n",
       "0        0.240700  26-08-2021 14:21:09  \n",
       "1        2.000000  26-08-2021 14:21:09  \n",
       "2        0.803063  26-08-2021 14:21:09  \n",
       "3        2.000000  26-08-2021 14:21:09  \n",
       "0        1.000000  26-08-2021 14:21:11  \n",
       "1       50.000000  26-08-2021 14:21:11  \n",
       "0        2.000000  26-08-2021 14:21:13  \n",
       "1      100.000000  26-08-2021 14:21:13  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cd543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
